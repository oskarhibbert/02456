{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK\n",
    "\n",
    "## DOCUMENT PREAMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Configure matplotlib\n",
    "tqdm.pandas()\n",
    "plt.style.use(\"classic\")\n",
    "#plt.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set document parameters\n",
    "data_version = \"demo\"\n",
    "data_type = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from parquet files\n",
    "def load_data(data_version, data_type, print_info=False):\n",
    "    if data_type not in [\"train\", \"validation\"]:\n",
    "        raise ValueError(\"data_type must be either 'train' or 'validation'\")\n",
    "\n",
    "    # Read parquet files into DataFrames\n",
    "    behaviors_df = pd.read_parquet(\n",
    "        f\"./data/ebnerd_{data_version}/{data_type}/behaviors.parquet\"\n",
    "    )\n",
    "    history_df = pd.read_parquet(f\"./data/ebnerd_{data_version}/{data_type}/history.parquet\")\n",
    "    articles_df = pd.read_parquet(f\"./data/ebnerd_{data_version}/articles.parquet\")\n",
    "\n",
    "    # Print DataFrame info\n",
    "    if print_info:\n",
    "        for name, df in zip(\n",
    "            [f\"{data_type}/behaviors\", f\"{data_type}/history\", \"articles\"],\n",
    "            [behaviors_df, history_df, articles_df],\n",
    "        ):\n",
    "            print(f\"--- '{name}' ---\\n\")\n",
    "            print(df.info(), \"\\n\")\n",
    "\n",
    "    return behaviors_df, history_df, articles_df\n",
    "\n",
    "# Load data\n",
    "behaviors_df, history_df, articles_df = load_data(data_version, data_type, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from parquet files\n",
    "def load_data(version, data_type, print_info=False):\n",
    "    base_path = f\"./data_processed/{version}_{data_type}_\"\n",
    "    files = [\"behaviors_df_expanded.parquet\", \"history_df_expanded.parquet\", \"articles_df_expanded.parquet\", \"users_df_expanded.parquet\"]\n",
    "    dataframes = [pd.read_parquet(f\"{base_path}{file}\") for file in files]\n",
    "    \n",
    "    if print_info:\n",
    "        for df in dataframes:\n",
    "            print(df.info(), \"\\n\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Load users_df\n",
    "_, _, _, users_df = load_data(data_version, data_type, print_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'article_ids_clicked' has more than 1 element\n",
    "behaviors_df = behaviors_df[behaviors_df['article_ids_clicked'].apply(lambda x: len(x) <= 1)]\n",
    "\n",
    "# Convert the list to an integer value\n",
    "behaviors_df['article_ids_clicked'] = behaviors_df['article_ids_clicked'].apply(lambda x: x[0] if x else None).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge history_df into behaviors_df\n",
    "df = behaviors_df.merge(\n",
    "    history_df,\n",
    "    how='inner',\n",
    "    left_on=['user_id'],\n",
    "    right_on=['user_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge articles_df into df\n",
    "df = df.merge(\n",
    "    articles_df.add_prefix('clicked_article_'),\n",
    "    how='inner',\n",
    "    left_on=['article_ids_clicked'],\n",
    "    right_on=['clicked_article_article_id']\n",
    ")\n",
    "\n",
    "# Drop 'clicked_article_article_id' column\n",
    "df = df.drop(columns=['clicked_article_article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impression_id                                                                  23290797\n",
      "article_id                                                                    9777492.0\n",
      "impression_time                                                     2023-05-24 07:22:14\n",
      "read_time                                                                          52.0\n",
      "scroll_percentage                                                                 100.0\n",
      "device_type                                                                           3\n",
      "article_ids_inview                    [9778386, 9777034, 9778007, 9778448, 9759955, ...\n",
      "article_ids_clicked                                                             9778413\n",
      "user_id                                                                          667805\n",
      "is_sso_user                                                                       False\n",
      "gender                                                                              NaN\n",
      "postcode                                                                            NaN\n",
      "age                                                                                 NaN\n",
      "is_subscriber                                                                     False\n",
      "session_id                                                                       127693\n",
      "next_read_time                                                                      1.0\n",
      "next_scroll_percentage                                                             22.0\n",
      "impression_time_fixed                 [2023-04-27T13:12:09.000000, 2023-04-28T06:50:...\n",
      "scroll_percentage_fixed               [34.0, 100.0, 16.0, 100.0, 100.0, 100.0, 81.0,...\n",
      "article_id_fixed                      [9738528, 9739916, 9735579, 9739916, 9739471, ...\n",
      "read_time_fixed                       [10.0, 54.0, 16.0, 13.0, 96.0, 9.0, 12.0, 105....\n",
      "clicked_article_title                 Politi: Elev startede dødsbrand i Guyana efter...\n",
      "clicked_article_subtitle              Ifølge en kilde fra det sydamerikanske lands r...\n",
      "clicked_article_last_modified_time                                  2023-06-29 06:49:01\n",
      "clicked_article_premium                                                           False\n",
      "clicked_article_body                  Politiet mistænker en kvindelig elev for at ha...\n",
      "clicked_article_published_time                                      2023-05-23 23:23:07\n",
      "clicked_article_image_ids                                                     [9778416]\n",
      "clicked_article_article_type                                            article_default\n",
      "clicked_article_url                   https://ekstrabladet.dk/nyheder/politik/danskp...\n",
      "clicked_article_ner_clusters                                     [AFP, Guyana, Reuters]\n",
      "clicked_article_entity_groups                                           [ORG, LOC, ORG]\n",
      "clicked_article_topics                [Kriminalitet, Personfarlig kriminalitet, Kata...\n",
      "clicked_article_category                                                            118\n",
      "clicked_article_subcategory                                                  [130, 131]\n",
      "clicked_article_category_str                                                    nyheder\n",
      "clicked_article_total_inviews                                                  343704.0\n",
      "clicked_article_total_pageviews                                                 83159.0\n",
      "clicked_article_total_read_time                                               3226794.0\n",
      "clicked_article_sentiment_score                                                  0.9958\n",
      "clicked_article_sentiment_label                                                Negative\n",
      "user_most_categories                  [nyheder, underholdning, krimi, sport, natione...\n",
      "user_most_subcategories               [133, 130, 131, 433, 425, 127, 123, 429, 432, ...\n",
      "user_avg_sentiment_score                                                       0.897511\n",
      "user_total_premium_viewed                                                            18\n",
      "user_avg_scroll_percentage                                                    86.577049\n",
      "user_avg_read_time                                                            40.675762\n",
      "user_total_articles_viewed                                                          316\n",
      "user_most_topics                      [Samfund, Kendt, Politik, Kriminalitet, Katast...\n",
      "user_most_ner_clusters                [Ekstra Bladet, Danmark, Facebook, Twitter, CN...\n",
      "user_least_categories                 [penge, ferie, musik, forbrug, nationen, sport...\n",
      "user_least_subcategories              [229, 337, 347, 553, 334, 343, 316, 2508, 271,...\n",
      "user_least_topics                     [Forbrugerelektronik, Naturvidenskab, Videregå...\n",
      "user_least_ner_clusters               [HK Kommunal Hovedstaden, FH Hovedstaden, Ulla...\n",
      "Name: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Merge users_df into df\n",
    "df = df.merge(\n",
    "    users_df,\n",
    "    how='inner',\n",
    "    left_on=['user_id'],\n",
    "    right_on=['user_id']\n",
    ")\n",
    "\n",
    "print(df.iloc[1000].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series mapping article_ids_clicked to topics for quick lookup\n",
    "article_topics_map = df.set_index('article_ids_clicked')['clicked_article_topics'].to_dict()\n",
    "\n",
    "# Precompute the impression times window for each article\n",
    "impressions_df = df[['impression_time', 'article_ids_clicked']]\n",
    "\n",
    "# Create a dictionary to store trendiness scores\n",
    "trendiness_scores = {}\n",
    "\n",
    "# Use tqdm to wrap the outer loop for progress tracking\n",
    "for article_ids_clicked, group in tqdm(impressions_df.groupby('article_ids_clicked'), desc=\"Calculating Trendiness\"):\n",
    "    # Get the topics for the current article\n",
    "    topics = article_topics_map.get(article_ids_clicked, [])\n",
    "    \n",
    "    # Calculate trendiness for each impression time in the group\n",
    "    for impression_time in group['impression_time']:\n",
    "        start_time = impression_time - pd.Timedelta(days=7)\n",
    "        \n",
    "        # Filter impressions in the time window\n",
    "        relevant_impressions = impressions_df[\n",
    "            (impressions_df['impression_time'] >= start_time) &\n",
    "            (impressions_df['impression_time'] < impression_time)\n",
    "        ]\n",
    "        \n",
    "        # Calculate trendiness by checking topic overlap\n",
    "        trendiness = relevant_impressions['article_ids_clicked'].apply(\n",
    "            lambda x: any(topic in article_topics_map.get(x, []) for topic in topics)\n",
    "        ).sum()\n",
    "        \n",
    "        # Store the trendiness score\n",
    "        trendiness_scores[(article_ids_clicked, impression_time)] = trendiness\n",
    "\n",
    "# Map the trendiness scores back to the df\n",
    "df['trendiness'] = df.apply(\n",
    "    lambda row: trendiness_scores.get((row['article_ids_clicked'], row['impression_time']), 0), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.join('data_processed', f'DATA1.parquet')\n",
    "df.to_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = os.path.join('data_processed', 'DATA1.parquet')\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  article_ids_clicked\n",
      "0        22779              9759966\n",
      "1       150224              9778661\n",
      "2       160892              9777856\n",
      "3      1001055              9776566\n",
      "4      1001055              9776553\n",
      "...        ...                  ...\n",
      "24589  2053999              9775562\n",
      "24590  2053999              9775361\n",
      "24591  2060487              9775699\n",
      "24592  2060487              9758424\n",
      "24593  2096611              9770369\n",
      "\n",
      "[24594 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[['user_id', 'article_ids_clicked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24594 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24594/24594 [00:08<00:00, 2838.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Precompute the impression times window for each article\n",
    "impressions_df = df[['user_id', 'impression_time', 'article_ids_inview']]\n",
    "\n",
    "# Convert 'article_ids_inview' and 'article_ids_clicked' to lists explicitly\n",
    "def convert_to_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif isinstance(x, str):\n",
    "        return x.strip('[]').replace(\"'\", \"\").split(', ')\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        return x.tolist()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "df['article_ids_inview'] = df['article_ids_inview'].apply(convert_to_list)\n",
    "\n",
    "# seen_before_clicked calculation function\n",
    "def calculate_seen_before_clicked(user_id, article_id, impression_time, hours=48):\n",
    "    start_time = impression_time - pd.Timedelta(hours=hours)\n",
    "    relevant_impressions = impressions_df[\n",
    "        (impressions_df['user_id'] == user_id) &\n",
    "        (impressions_df['impression_time'] >= start_time) & \n",
    "        (impressions_df['impression_time'] < impression_time)\n",
    "    ]\n",
    "    seen_before_clicked = relevant_impressions['article_ids_inview'].apply(lambda x: article_id in x).sum()\n",
    "    return seen_before_clicked\n",
    "\n",
    "# Apply the function with a progress bar\n",
    "df['seen_before_clicked'] = df.progress_apply(\n",
    "    lambda row: calculate_seen_before_clicked(row['user_id'], row['article_id'], row['impression_time']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  article_ids_clicked  seen_before_clicked\n",
      "0        22779              9759966                    0\n",
      "1       150224              9778661                    0\n",
      "2       160892              9777856                    0\n",
      "3      1001055              9776566                    0\n",
      "4      1001055              9776553                    0\n",
      "...        ...                  ...                  ...\n",
      "24589  2053999              9775562                    0\n",
      "24590  2053999              9775361                    0\n",
      "24591  2060487              9775699                    0\n",
      "24592  2060487              9758424                    1\n",
      "24593  2096611              9770369                    0\n",
      "\n",
      "[24594 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[['user_id', 'article_ids_clicked', 'seen_before_clicked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Article Delay\n",
    "df['article_delay'] = (df['impression_time'] - df['clicked_article_published_time']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['impression_hour'] = df['impression_time'].dt.hour\n",
    "df['impression_day_of_week'] = df['impression_time'].dt.dayofweek\n",
    "\n",
    "# Convert time of day and day of week to cyclical features\n",
    "df['impression_hour_sin'] = np.sin(2 * np.pi * df['impression_hour'] / 24)\n",
    "df['impression_hour_cos'] = np.cos(2 * np.pi * df['impression_hour'] / 24)\n",
    "df['impression_day_of_week_sin'] = np.sin(2 * np.pi * df['impression_day_of_week'] / 7)\n",
    "df['impression_day_of_week_cos'] = np.cos(2 * np.pi * df['impression_day_of_week'] / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>ner_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9759966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9778661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9777856</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9776566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9776553</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24589</th>\n",
       "      <td>9775562</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24590</th>\n",
       "      <td>9775361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24591</th>\n",
       "      <td>9775699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24592</th>\n",
       "      <td>9758424</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24593</th>\n",
       "      <td>9770369</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24594 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_ids_clicked  ner_similarity\n",
       "0                  9759966             0.0\n",
       "1                  9778661             0.0\n",
       "2                  9777856             0.0\n",
       "3                  9776566             0.0\n",
       "4                  9776553             0.0\n",
       "...                    ...             ...\n",
       "24589              9775562             0.0\n",
       "24590              9775361             0.0\n",
       "24591              9775699             0.0\n",
       "24592              9758424             0.0\n",
       "24593              9770369             0.0\n",
       "\n",
       "[24594 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ner_clusters(article_ids, articles_df):\n",
    "    # Filter the articles_df to get NER clusters for the given article IDs\n",
    "    clusters = articles_df[articles_df['article_id'].isin(article_ids)]['ner_clusters']\n",
    "    # Flatten the list of lists and join into a single string\n",
    "    return ' '.join([item for sublist in clusters for item in sublist])\n",
    "\n",
    "# Extract NER clusters for each article_id_fixed\n",
    "df['article_ner_clusters'] = df['article_id_fixed'].apply(lambda ids: get_ner_clusters(ids, articles_df))\n",
    "\n",
    "# Convert the clicked_article_ner_clusters to strings\n",
    "df['clicked_article_ner_clusters_str'] = df['clicked_article_ner_clusters'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Combine all NER cluster strings for TF-IDF computation\n",
    "corpus = pd.concat([df['clicked_article_ner_clusters_str'], df['article_ner_clusters']])\n",
    "\n",
    "# Create a TF-IDF vectoriser and fit it to the corpus\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Calculate cosine similarity between clicked NER clusters and article NER clusters\n",
    "def calculate_similarity(row_index):\n",
    "    # Compute similarity between the clicked NER and article NER for each row\n",
    "    return cosine_similarity(tfidf_matrix[row_index], tfidf_matrix[row_index + len(df)])[0][0]\n",
    "\n",
    "# Apply similarity calculation for each row\n",
    "df['ner_similarity'] = [calculate_similarity(i) for i in range(len(df))]\n",
    "\n",
    "# Display the results\n",
    "df[['article_ids_clicked', 'ner_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
